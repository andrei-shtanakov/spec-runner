#!/usr/bin/env python3
"""
ATP Task Executor ‚Äî automated task execution via Claude CLI

Usage:
    python executor.py run                    # Execute the next task
    python executor.py run --task=TASK-001    # Execute a specific task
    python executor.py run --all              # Execute all ready tasks
    python executor.py run --milestone=mvp    # Execute tasks for a milestone
    python executor.py status                 # Execution status
    python executor.py retry TASK-001         # Retry a failed task
    python executor.py logs TASK-001          # Task logs
"""

import os
import re
import sys
import json
import subprocess
import argparse
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass, field
from typing import Optional
import shutil

# Import task parser
from task import parse_tasks, get_task_by_id, get_next_tasks, update_task_status, Task, TASKS_FILE

# === Configuration ===

@dataclass
class ExecutorConfig:
    """Executor configuration"""
    max_retries: int = 3                    # Max attempts per task
    retry_delay_seconds: int = 5            # Delay between retries
    task_timeout_minutes: int = 30          # Timeout per task
    max_consecutive_failures: int = 2       # Stop after N consecutive failures

    # Claude CLI
    claude_command: str = "claude"          # Claude CLI command
    claude_model: str = ""                  # Model (empty = default)

    # Hooks
    run_tests_on_done: bool = True          # Run tests on completion
    create_git_branch: bool = True          # Create branch on start
    auto_commit: bool = False               # Auto-commit on success
    
    # Paths
    project_root: Path = Path(".")
    logs_dir: Path = Path("spec/.executor-logs")
    state_file: Path = Path("spec/.executor-state.json")
    
    # Test command
    test_command: str = "make test-fast"
    lint_command: str = "make lint"


# === State Management ===

@dataclass
class TaskAttempt:
    """Task execution attempt"""
    timestamp: str
    success: bool
    duration_seconds: float
    error: Optional[str] = None
    claude_output: Optional[str] = None

@dataclass
class TaskState:
    """Task state in executor"""
    task_id: str
    status: str  # pending, running, success, failed, skipped
    attempts: list = field(default_factory=list)
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    
    @property
    def attempt_count(self) -> int:
        return len(self.attempts)
    
    @property
    def last_error(self) -> Optional[str]:
        if self.attempts:
            return self.attempts[-1].error
        return None


class ExecutorState:
    """Global executor state"""
    
    def __init__(self, config: ExecutorConfig):
        self.config = config
        self.tasks: dict[str, TaskState] = {}
        self.consecutive_failures = 0
        self.total_completed = 0
        self.total_failed = 0
        self._load()
    
    def _load(self):
        """Load state from file"""
        if self.config.state_file.exists():
            data = json.loads(self.config.state_file.read_text())
            for task_id, task_data in data.get("tasks", {}).items():
                attempts = [
                    TaskAttempt(**a) for a in task_data.get("attempts", [])
                ]
                self.tasks[task_id] = TaskState(
                    task_id=task_id,
                    status=task_data.get("status", "pending"),
                    attempts=attempts,
                    started_at=task_data.get("started_at"),
                    completed_at=task_data.get("completed_at"),
                )
            self.consecutive_failures = data.get("consecutive_failures", 0)
            self.total_completed = data.get("total_completed", 0)
            self.total_failed = data.get("total_failed", 0)
    
    def _save(self):
        """Save state to file"""
        self.config.state_file.parent.mkdir(parents=True, exist_ok=True)
        data = {
            "tasks": {
                task_id: {
                    "status": ts.status,
                    "attempts": [
                        {
                            "timestamp": a.timestamp,
                            "success": a.success,
                            "duration_seconds": a.duration_seconds,
                            "error": a.error,
                        }
                        for a in ts.attempts
                    ],
                    "started_at": ts.started_at,
                    "completed_at": ts.completed_at,
                }
                for task_id, ts in self.tasks.items()
            },
            "consecutive_failures": self.consecutive_failures,
            "total_completed": self.total_completed,
            "total_failed": self.total_failed,
            "last_updated": datetime.now().isoformat(),
        }
        self.config.state_file.write_text(json.dumps(data, indent=2))
    
    def get_task_state(self, task_id: str) -> TaskState:
        if task_id not in self.tasks:
            self.tasks[task_id] = TaskState(task_id=task_id, status="pending")
        return self.tasks[task_id]
    
    def record_attempt(self, task_id: str, success: bool, duration: float, 
                       error: Optional[str] = None, output: Optional[str] = None):
        """Record an execution attempt"""
        state = self.get_task_state(task_id)
        state.attempts.append(TaskAttempt(
            timestamp=datetime.now().isoformat(),
            success=success,
            duration_seconds=duration,
            error=error,
            claude_output=output,
        ))
        
        if success:
            state.status = "success"
            state.completed_at = datetime.now().isoformat()
            self.consecutive_failures = 0
            self.total_completed += 1
        else:
            if state.attempt_count >= self.config.max_retries:
                state.status = "failed"
                self.total_failed += 1
            self.consecutive_failures += 1
        
        self._save()
    
    def mark_running(self, task_id: str):
        state = self.get_task_state(task_id)
        state.status = "running"
        state.started_at = datetime.now().isoformat()
        self._save()
    
    def should_stop(self) -> bool:
        """Check if we should stop"""
        return self.consecutive_failures >= self.config.max_consecutive_failures


# === Prompt Builder ===

def build_task_prompt(task: Task, config: ExecutorConfig) -> str:
    """Build a prompt for Claude with task context"""
    
    # Read specifications
    spec_dir = config.project_root / "spec"
    
    requirements = ""
    if (spec_dir / "requirements.md").exists():
        requirements = (spec_dir / "requirements.md").read_text()
    
    design = ""
    if (spec_dir / "design.md").exists():
        design = (spec_dir / "design.md").read_text()
    
    # Find related requirements
    related_reqs = []
    for ref in task.traces_to:
        if ref.startswith("REQ-"):
            # Extract requirement from requirements.md
            pattern = rf'#### {ref}:.*?(?=####|\Z)'
            match = re.search(pattern, requirements, re.DOTALL)
            if match:
                related_reqs.append(match.group(0).strip())
    
    # Find related design
    related_design = []
    for ref in task.traces_to:
        if ref.startswith("DESIGN-"):
            pattern = rf'### {ref}:.*?(?=###|\Z)'
            match = re.search(pattern, design, re.DOTALL)
            if match:
                related_design.append(match.group(0).strip())
    
    # Checklist
    checklist_text = "\n".join([
        f"- {'[x]' if done else '[ ]'} {item}"
        for item, done in task.checklist
    ])
    
    prompt = f"""# Task Execution Request

## Task: {task.id} ‚Äî {task.name}

**Priority:** {task.priority.upper()}
**Estimate:** {task.estimate}
**Milestone:** {task.milestone}

## Checklist (implement ALL items):

{checklist_text}

## Related Requirements:

{chr(10).join(related_reqs) if related_reqs else "See spec/requirements.md"}

## Related Design:

{chr(10).join(related_design) if related_design else "See spec/design.md"}

## Instructions:

1. Implement ALL checklist items for this task
2. Write unit tests for new code (coverage ‚â•80%)
3. Follow the design patterns from spec/design.md
4. Use existing code style and conventions
5. Create/update files as needed

## Success Criteria:

- All checklist items implemented
- All tests pass (`make test`)
- No lint errors (`make lint`)
- Code follows project conventions

## Output:

When complete, respond with:
- Summary of changes made
- Files created/modified
- Any issues or notes
- "TASK_COMPLETE" if successful, or "TASK_FAILED: <reason>" if not

Begin implementation:
"""
    
    return prompt


# === Hooks ===

def pre_start_hook(task: Task, config: ExecutorConfig) -> bool:
    """Pre-task start hook"""
    print(f"üîß Pre-start hook for {task.id}")
    
    # Create git branch
    if config.create_git_branch:
        branch_name = f"task/{task.id.lower()}-{task.name.lower().replace(' ', '-')[:30]}"
        try:
            # Check if git is available
            result = subprocess.run(
                ["git", "rev-parse", "--git-dir"],
                capture_output=True,
                cwd=config.project_root
            )
            if result.returncode == 0:
                # Create branch
                subprocess.run(
                    ["git", "checkout", "-b", branch_name],
                    capture_output=True,
                    cwd=config.project_root
                )
                print(f"   Created branch: {branch_name}")
        except FileNotFoundError:
            pass  # git not installed
    
    return True


def post_done_hook(task: Task, config: ExecutorConfig, success: bool) -> bool:
    """Post-task completion hook"""
    print(f"üîß Post-done hook for {task.id} (success={success})")
    
    if not success:
        return False
    
    # Run tests
    if config.run_tests_on_done:
        print("   Running tests...")
        result = subprocess.run(
            config.test_command,
            shell=True,
            capture_output=True,
            cwd=config.project_root
        )
        if result.returncode != 0:
            print(f"   ‚ùå Tests failed!")
            print(result.stderr.decode()[:500])
            return False
        print("   ‚úÖ Tests passed")
    
    # Run lint
    if config.lint_command:
        print("   Running lint...")
        result = subprocess.run(
            config.lint_command,
            shell=True,
            capture_output=True,
            cwd=config.project_root
        )
        if result.returncode != 0:
            print(f"   ‚ö†Ô∏è  Lint warnings (non-blocking)")
    
    # Auto-commit
    if config.auto_commit:
        try:
            subprocess.run(
                ["git", "add", "-A"],
                cwd=config.project_root
            )
            subprocess.run(
                ["git", "commit", "-m", f"{task.id}: {task.name}"],
                cwd=config.project_root
            )
            print(f"   Committed changes")
        except Exception as e:
            print(f"   Commit failed: {e}")
    
    return True


# === Task Executor ===

def execute_task(task: Task, config: ExecutorConfig, state: ExecutorState) -> bool:
    """Execute a single task via Claude CLI"""
    
    task_id = task.id
    print(f"\n{'='*60}")
    print(f"üöÄ Executing {task_id}: {task.name}")
    print(f"{'='*60}")
    
    # Pre-start hook
    if not pre_start_hook(task, config):
        print("‚ùå Pre-start hook failed")
        return False
    
    # Update status
    state.mark_running(task_id)
    update_task_status(TASKS_FILE, task_id, 'in_progress')
    
    # Build prompt
    prompt = build_task_prompt(task, config)
    
    # Save prompt to log
    config.logs_dir.mkdir(parents=True, exist_ok=True)
    log_file = config.logs_dir / f"{task_id}-{datetime.now().strftime('%Y%m%d-%H%M%S')}.log"
    
    with open(log_file, 'w') as f:
        f.write(f"=== PROMPT ===\n{prompt}\n\n")
    
    # Run Claude
    start_time = datetime.now()
    
    try:
        cmd = [config.claude_command, "-p", prompt]
        if config.claude_model:
            cmd.extend(["--model", config.claude_model])
        
        print(f"ü§ñ Running: {' '.join(cmd[:3])}...")
        
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=config.task_timeout_minutes * 60,
            cwd=config.project_root
        )
        
        duration = (datetime.now() - start_time).total_seconds()
        output = result.stdout
        
        # Save output
        with open(log_file, 'a') as f:
            f.write(f"=== OUTPUT ===\n{output}\n\n")
            f.write(f"=== STDERR ===\n{result.stderr}\n\n")
            f.write(f"=== RETURN CODE: {result.returncode} ===\n")
        
        # Check result
        success = "TASK_COMPLETE" in output and "TASK_FAILED" not in output
        
        if success:
            print(f"‚úÖ Claude reports: TASK_COMPLETE")
            
            # Post-done hook (tests, lint)
            hook_success = post_done_hook(task, config, True)
            
            if hook_success:
                state.record_attempt(task_id, True, duration, output=output)
                update_task_status(TASKS_FILE, task_id, 'done')
                print(f"‚úÖ {task_id} completed successfully in {duration:.1f}s")
                return True
            else:
                # Hook failed (tests did not pass)
                error = "Post-done hook failed (tests/lint)"
                state.record_attempt(task_id, False, duration, error=error, output=output)
                print(f"‚ùå {task_id} failed: {error}")
                return False
        else:
            # Claude reported failure
            error_match = re.search(r'TASK_FAILED:\s*(.+)', output)
            error = error_match.group(1) if error_match else "Unknown error"
            state.record_attempt(task_id, False, duration, error=error, output=output)
            print(f"‚ùå {task_id} failed: {error}")
            return False
            
    except subprocess.TimeoutExpired:
        duration = config.task_timeout_minutes * 60
        error = f"Timeout after {config.task_timeout_minutes} minutes"
        state.record_attempt(task_id, False, duration, error=error)
        print(f"‚è∞ {task_id} timed out")
        return False
        
    except Exception as e:
        duration = (datetime.now() - start_time).total_seconds()
        error = str(e)
        state.record_attempt(task_id, False, duration, error=error)
        print(f"üí• {task_id} error: {error}")
        return False


def run_with_retries(task: Task, config: ExecutorConfig, state: ExecutorState) -> bool:
    """Execute task with retries"""
    
    task_state = state.get_task_state(task.id)
    
    for attempt in range(task_state.attempt_count, config.max_retries):
        print(f"\nüìç Attempt {attempt + 1}/{config.max_retries} for {task.id}")
        
        if execute_task(task, config, state):
            return True
        
        if attempt < config.max_retries - 1:
            print(f"‚è≥ Waiting {config.retry_delay_seconds}s before retry...")
            import time
            time.sleep(config.retry_delay_seconds)
    
    print(f"‚ùå {task.id} failed after {config.max_retries} attempts")
    update_task_status(TASKS_FILE, task.id, 'blocked')
    return False


# === CLI Commands ===

def cmd_run(args, config: ExecutorConfig):
    """Execute tasks"""
    
    tasks = parse_tasks(TASKS_FILE)
    state = ExecutorState(config)
    
    # Check failure limit
    if state.should_stop():
        print(f"‚õî Stopped: {state.consecutive_failures} consecutive failures")
        print("   Use 'executor.py retry <TASK-ID>' to retry specific task")
        return
    
    # Determine which tasks to run
    if args.task:
        # Specific task
        task = get_task_by_id(tasks, args.task.upper())
        if not task:
            print(f"‚ùå Task {args.task} not found")
            return
        tasks_to_run = [task]
    
    elif args.all:
        # All ready tasks
        tasks_to_run = get_next_tasks(tasks)
        if args.milestone:
            tasks_to_run = [t for t in tasks_to_run 
                          if args.milestone.lower() in t.milestone.lower()]
    
    elif args.milestone:
        # Tasks for specific milestone
        next_tasks = get_next_tasks(tasks)
        tasks_to_run = [t for t in next_tasks 
                       if args.milestone.lower() in t.milestone.lower()]
    
    else:
        # Next task
        next_tasks = get_next_tasks(tasks)
        tasks_to_run = next_tasks[:1] if next_tasks else []
    
    if not tasks_to_run:
        print("‚úÖ No tasks ready to execute")
        print("   All dependencies might be incomplete, or all tasks done")
        return
    
    print(f"üìã Tasks to execute: {len(tasks_to_run)}")
    for t in tasks_to_run:
        print(f"   - {t.id}: {t.name}")
    
    # Execute
    for task in tasks_to_run:
        success = run_with_retries(task, config, state)
        
        if not success and state.should_stop():
            print(f"\n‚õî Stopping: too many consecutive failures")
            break
    
    # Summary
    print(f"\n{'='*60}")
    print(f"üìä Execution Summary")
    print(f"{'='*60}")
    print(f"   Completed: {state.total_completed}")
    print(f"   Failed:    {state.total_failed}")
    print(f"   Remaining: {len([t for t in tasks if t.status == 'todo'])}")


def cmd_status(args, config: ExecutorConfig):
    """Execution status"""
    
    state = ExecutorState(config)
    tasks = parse_tasks(TASKS_FILE)
    
    print(f"\nüìä Executor Status")
    print(f"{'='*50}")
    print(f"Total completed:       {state.total_completed}")
    print(f"Total failed:          {state.total_failed}")
    print(f"Consecutive failures:  {state.consecutive_failures}/{config.max_consecutive_failures}")
    
    # Tasks with attempts
    attempted = [ts for ts in state.tasks.values() if ts.attempts]
    if attempted:
        print(f"\nüìù Task History:")
        for ts in attempted:
            icon = "‚úÖ" if ts.status == "success" else "‚ùå" if ts.status == "failed" else "üîÑ"
            print(f"   {icon} {ts.task_id}: {ts.status} ({ts.attempt_count} attempts)")
            if ts.last_error:
                print(f"      Last error: {ts.last_error[:50]}...")


def cmd_retry(args, config: ExecutorConfig):
    """Retry a failed task"""
    
    tasks = parse_tasks(TASKS_FILE)
    state = ExecutorState(config)
    
    task = get_task_by_id(tasks, args.task_id.upper())
    if not task:
        print(f"‚ùå Task {args.task_id} not found")
        return
    
    # Reset state
    task_state = state.get_task_state(task.id)
    task_state.attempts = []
    task_state.status = "pending"
    state.consecutive_failures = 0
    state._save()
    
    print(f"üîÑ Retrying {task.id}...")
    run_with_retries(task, config, state)


def cmd_logs(args, config: ExecutorConfig):
    """Show task logs"""
    
    task_id = args.task_id.upper()
    log_files = sorted(config.logs_dir.glob(f"{task_id}-*.log"))
    
    if not log_files:
        print(f"No logs found for {task_id}")
        return
    
    latest = log_files[-1]
    print(f"üìÑ Latest log: {latest}")
    print("=" * 50)
    print(latest.read_text()[:5000])  # Limit output


def cmd_reset(args, config: ExecutorConfig):
    """Reset executor state"""
    
    if config.state_file.exists():
        config.state_file.unlink()
        print("‚úÖ State reset")
    
    if args.logs and config.logs_dir.exists():
        shutil.rmtree(config.logs_dir)
        print("‚úÖ Logs cleared")


# === Main ===

def main():
    parser = argparse.ArgumentParser(
        description='ATP Task Executor ‚Äî automated task execution via Claude',
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    
    # Global options
    parser.add_argument('--max-retries', type=int, default=3,
                       help='Max retries per task (default: 3)')
    parser.add_argument('--timeout', type=int, default=30,
                       help='Task timeout in minutes (default: 30)')
    parser.add_argument('--no-tests', action='store_true',
                       help='Skip tests on task completion')
    parser.add_argument('--no-branch', action='store_true',
                       help='Skip git branch creation')
    parser.add_argument('--auto-commit', action='store_true',
                       help='Auto-commit on success')
    
    subparsers = parser.add_subparsers(dest='command', help='Commands')
    
    # run
    run_parser = subparsers.add_parser('run', help='Execute tasks')
    run_parser.add_argument('--task', '-t', help='Specific task ID')
    run_parser.add_argument('--all', '-a', action='store_true', 
                           help='Run all ready tasks')
    run_parser.add_argument('--milestone', '-m', help='Filter by milestone')
    
    # status
    subparsers.add_parser('status', help='Show execution status')
    
    # retry
    retry_parser = subparsers.add_parser('retry', help='Retry failed task')
    retry_parser.add_argument('task_id', help='Task ID to retry')
    
    # logs
    logs_parser = subparsers.add_parser('logs', help='Show task logs')
    logs_parser.add_argument('task_id', help='Task ID')
    
    # reset
    reset_parser = subparsers.add_parser('reset', help='Reset executor state')
    reset_parser.add_argument('--logs', action='store_true', 
                             help='Also clear logs')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # Build config
    config = ExecutorConfig(
        max_retries=args.max_retries,
        task_timeout_minutes=args.timeout,
        run_tests_on_done=not args.no_tests,
        create_git_branch=not args.no_branch,
        auto_commit=args.auto_commit,
    )
    
    # Dispatch
    commands = {
        'run': cmd_run,
        'status': cmd_status,
        'retry': cmd_retry,
        'logs': cmd_logs,
        'reset': cmd_reset,
    }
    
    cmd_func = commands.get(args.command)
    if cmd_func:
        cmd_func(args, config)


if __name__ == '__main__':
    main()
